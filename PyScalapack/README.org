#+OPTIONS: toc:nil

* PyScalapack

PyScalapack is a python wrapper for scalapack.

** Documents

#+begin_src emacs-lisp :exports none :results silent
  (defun ek/babel-ansi ()
    (when-let ((beg (org-babel-where-is-src-block-result nil nil)))
      (save-excursion
        (goto-char beg)
        (when (looking-at org-babel-result-regexp)
          (let ((end (org-babel-result-end))
                (ansi-color-context-region nil))
            (ansi-color-apply-on-region beg end))))))
  (add-hook 'org-babel-after-execute-hook 'ek/babel-ansi)
  (setq org-babel-min-lines-for-block-output 1)
#+end_src

*** Load scalapack

It is needed to load scalapack dynamic linked library at first of all step.

#+begin_src python :results output :exports both
  import PyScalapack

  scalapack = PyScalapack("libscalapack.so")
#+end_src

#+RESULTS:

If the scalapack functions are placed in several different cdecl convention dynamic shared library, pass them all into =PyScalapack=.
For examples, =PyScalapack("libmkl_scalapack_lp64.so", "libmkl_blacs_openmpi_lp64.so", ...)=.

*** Create a context

Create a blacs context to do other blacs or scalapack operator. Scalapack use blacs context to describe how a distributed matrix placed in different processes.
A context is needed to create a blacs matrix. The only three arguments to create an context are layout(column major or row major),
row of process grid and column of process grid, please ensure =nprow * npcol = size= to avoid process idling.
The layout should be =b'C'= for column major or =b'R'= for row major.

#+begin_src python :results output :exports both
  import PyScalapack

  scalapack = PyScalapack("libscalapack.so")

  with scalapack(layout=b'C', nprow=1, npcol=1) as context:
      print("Blacs raw ictx handle:", context.ictxt)
      print("Process grid rank and size:", context.rank, context.size)
      print("Process grid layout:", context.layout)
      print("Process grid shape:", context.nprow, context.npcol)
      print("Current process index grid:", context.myrow, context.mycol)
      print("Whether current process is valid in the grid:", context.valid)
#+end_src

#+RESULTS:
#+begin_example
Blacs raw ictx handle: c_int(0)
Process grid rank and size: c_int(0) c_int(1)
Process grid layout: c_char(b'C')
Process grid shape: c_int(1) c_int(1)
Current process index grid: c_int(0) c_int(0)
Whether current process is valid in the grid: True
#+end_example

When =nprow * npcol < size=, some process are not considered a part of context, these kind of process in =PyScalapack= is marked as invalid.

**** Barrier

You can call =context.barrier(scope=b'A')= to synchronize all process in the process grid,
call =context.barrier(scope=b'R')= to synchronize all process in the same row of the process grid,
or call =context.barrier(scope=b'C')= to synchronize all process in the same column of the process grid.

*** Create an array

Create a blacs array. =m= and =n= is the shape of the matrix. =mb= and =nb= is the block size of the matrix to distributed to different processes.
After distributed to process grid, every process has its own local matrix shape, which could be obtained by =local_m= and =local_n=.

#+begin_src python :results output :exports both :python LD_LIBRARY_PATH=/opt/intel/oneapi/mkl/latest/lib/intel64 /opt/intel/oneapi/mpi/latest/bin/mpirun -n 4 -s all python
  import numpy as np
  import PyScalapack

  scalapack = PyScalapack("libmpi.so", "libmkl_core.so", "libmkl_sequential.so", "libmkl_intel_lp64.so",
                          "libmkl_blacs_intelmpi_lp64.so", "libmkl_scalapack_lp64.so")

  with scalapack(b'C', 2, 2) as context:
      array = context.array(m=23, n=45, mb=2, nb=2, dtype=np.float64)
      if context.rank.value == 0:
          print(f"Matrix shape is {array.m} * {array.n}")
      print(f"Matrix local shape at ({context.myrow.value}, {context.mycol.value}) is {array.local_m} * {array.local_n}")
#+end_src

#+RESULTS:
#+begin_example
Matrix shape is 23 * 45
Matrix local shape at (0, 0) is 12 * 23
Matrix local shape at (1, 0) is 11 * 23
Matrix local shape at (0, 1) is 12 * 22
Matrix local shape at (1, 1) is 11 * 22
#+end_example

When creating the array, pass =dtype= to create a new matrix filled with zero in type =dtype=, or pass an existed numpy array by =data= to share its memory. For example,

#+begin_src python :results output :exports both
  import numpy as np
  import PyScalapack

  scalapack = PyScalapack("libscalapack.so")

  with scalapack(b'C', 1, 1) as context:
      array = context.array(m=128, n=512, mb=1, nb=1, data=np.zeros([128, 512], order='F'))
      print("Matrix shape:", array.m, array.n)
      print("Matrix local shape:", array.local_m, array.local_n)

  with scalapack(b'R', 1, 1) as context:
      array = context.array(m=128, n=512, mb=1, nb=1, data=np.zeros([128, 512], order='C'))
      print("Matrix shape:", array.m, array.n)
      print("Matrix local shape:", array.local_m, array.local_n)
#+end_src

#+RESULTS:
#+begin_example
Matrix shape: 128 512
Matrix local shape: 128 512
Matrix shape: 128 512
Matrix local shape: 128 512
#+end_example

You need to ensure the numpy order fits the the context layout, aka, =order= as 'F' for column major layout, =order= as 'C' for row major layout.
And for grid other than =1*1=, users need to prepare the correct matrix local shape first.

*** Redistribute array

In scalapack, =p?gemr2d= is used to redistribute an array.

#+begin_src python :results output :exports both :python LD_LIBRARY_PATH=/opt/intel/oneapi/mkl/latest/lib/intel64 /opt/intel/oneapi/mpi/latest/bin/mpirun -n 2 -s all python
  import numpy as np
  import PyScalapack

  scalapack = PyScalapack("libmpi.so", "libmkl_core.so", "libmkl_sequential.so", "libmkl_intel_lp64.so",
                          "libmkl_blacs_intelmpi_lp64.so", "libmkl_scalapack_lp64.so")

  with scalapack(b'C', 1, 2) as context1:
      with scalapack(b'C', 2, 1) as context2:
          m = 2
          n = 2
          array1 = context1.array(m=m, n=n, mb=1, nb=1, dtype=np.float64)
          array1.data[...] = np.random.randn(*array1.data.shape)
          print(f"rank={context1.rank.value} before redistribute {array1.data.reshape([-1])}")
          array2 = context2.array(m=m, n=n, mb=1, nb=1, dtype=np.float64)
          scalapack.pgemr2d["D"](
              ,*(m, n),
              ,*array1.scalapack_params(),
              ,*array2.scalapack_params(),
              context1.ictxt,
          )
          print(f"rank={context2.rank.value} after redistribute {array2.data.reshape([-1])}")
#+end_src

#+RESULTS:
#+begin_example
rank=0 before redistribute [ 1.0460689  -0.32543216]
rank=1 before redistribute [0.57973354 0.31722263]
rank=0 after redistribute [1.0460689  0.57973354]
rank=1 after redistribute [-0.32543216  0.31722263]
#+end_example

*** Call scalapack function

Call pdgemm and compare it to product calculated by numpy.

#+begin_src python :results output :exports both :python LD_LIBRARY_PATH=/opt/intel/oneapi/mkl/latest/lib/intel64 /opt/intel/oneapi/mpi/latest/bin/mpirun -n 4 -s all python
  import numpy as np
  import PyScalapack

  scalapack = PyScalapack("libmpi.so", "libmkl_core.so", "libmkl_sequential.so", "libmkl_intel_lp64.so",
                          "libmkl_blacs_intelmpi_lp64.so", "libmkl_scalapack_lp64.so")

  L1 = 128
  L2 = 512
  with scalapack(b'C', 2, 2) as context, scalapack(b'C', 1, 1) as context0:
      # Create array0 add 1*1 grid
      array0 = context0.array(m=L1, n=L2, mb=1, nb=1, dtype=np.float64)
      if context0:
          array0.data[...] = np.random.randn(*array0.data.shape)

      # Redistribute array0 to 2*2 grid as array
      array = context.array(m=L1, n=L2, mb=1, nb=1, dtype=np.float64)
      scalapack.pgemr2d["D"](*(L1, L2), *array0.scalapack_params(), *array.scalapack_params(), context.ictxt)

      # Call pdgemm to get the product of array and array in 2*2 grid
      result = context.array(m=L1, n=L1, mb=1, nb=1, dtype=np.float64)
      scalapack.pdgemm(
          b'N',
          b'T',
          ,*(L1, L1, L2),
          scalapack.d_one,
          ,*array.scalapack_params(),
          ,*array.scalapack_params(),
          scalapack.d_zero,
          ,*result.scalapack_params(),
      )

      # Redistribute result to 1*1 grid as result0
      result0 = context0.array(m=L1, n=L1, mb=1, nb=1, dtype=np.float64)
      scalapack.pgemr2d["D"](*(L1, L1), *result.scalapack_params(), *result0.scalapack_params(), context.ictxt)

      # Check result0 == array0 * array0^T
      if context0:
          diff = result0.data - array0.data @ array0.data.T
          print(np.linalg.norm(diff))
#+end_src

#+RESULTS:
#+begin_example
2.603367787519907e-12
#+end_example

**** Call lapack function

This package also provide interface to call LAPACK/BLAS functions.

#+begin_src python :results output :exports both
  import numpy as np
  import PyScalapack

  scalapack = PyScalapack("libscalapack.so")

  L1 = 128
  L2 = 512
  with scalapack(b'C', 1, 1) as context:
      array = context.array(m=L1, n=L2, mb=1, nb=1, dtype=np.float64)
      array.data[...] = np.random.randn(*array.data.shape)

      result = context.array(m=L1, n=L1, mb=1, nb=1, dtype=np.float64)
      scalapack.dgemm(
          b'N',
          b'T',
          ,*(L1, L1, L2),
          scalapack.d_one,
          ,*array.lapack_params(),
          ,*array.lapack_params(),
          scalapack.d_zero,
          ,*result.lapack_params(),
      )

      diff = result.data - array.data @ array.data.T
      print(np.linalg.norm(diff))
#+end_src

#+RESULTS:
#+begin_example
0.0
#+end_example

*** Generic variables and functions

=f_one= and =f_zero= is used to get the floating =1= and =0= by selected scalar type, which is useful sometimes.

#+begin_src python :results output :exports both
  import PyScalapack

  scalapack = PyScalapack("libscalapack.so")

  print(scalapack.f_one["D"] == scalapack.d_one)
  print(scalapack.f_zero["Z"] == scalapack.z_zero)
#+end_src

#+RESULTS:
#+begin_example
True
True
#+end_example

Some function such =p?gemm= could be selected by =pgemm[char]= where char is one of =S=, =D=, =C=, =Z=.
But this is not applied to all functions, since it is manully mapped. We only map the function we are
using currently. If you want to add some other scalapack functions, you could add the mapping by yourself,
or just create an issue or pull request.

#+begin_src python :results output :exports both
  import PyScalapack

  scalapack = PyScalapack("libscalapack.so")

  print(scalapack.pgemm["D"] == scalapack.pdgemm)
#+end_src

#+RESULTS:
#+begin_example
True
#+end_example
